import{_ as t,c as a,a1 as r,o as s}from"./chunks/framework.CjPQ6buQ.js";const m=JSON.parse('{"title":"OpenAI GPT-4o来袭 🤖🚀","description":"","frontmatter":{"title":"OpenAI GPT-4o来袭 🤖🚀","customTag":"blog>AIGC","editLink":true,"date":"2024.05.14"},"headers":[],"relativePath":"blog/open-ai-gpt-4o.md","filePath":"blog/open-ai-gpt-4o.md","lastUpdated":1727835117000}'),p={name:"blog/open-ai-gpt-4o.md"};function n(o,e,_,i,g,h){return s(),a("div",null,e[0]||(e[0]=[r('<p><img src="https://raw.githubusercontent.com/hua-bang/assert-store/master/Snipaste_2024-05-14_07-52-09.png" alt="Snipaste_2024-05-14_07-52-09.png"><img src="https://raw.githubusercontent.com/hua-bang/assert-store/master/Snipaste_2024-05-14_07-52-37.png" alt="Snipaste_2024-05-14_07-52-37.png"><img src="https://raw.githubusercontent.com/hua-bang/assert-store/master/Snipaste_2024-05-14_07-52-47.png" alt="Snipaste_2024-05-14_07-52-47.png"><img src="https://raw.githubusercontent.com/hua-bang/assert-store/master/Snipaste_2024-05-14_07-53-28.png" alt="Snipaste_2024-05-14_07-53-28.png"><img src="https://raw.githubusercontent.com/hua-bang/assert-store/master/Snipaste_2024-05-14_07-56-59.png" alt="Snipaste_2024-05-14_07-56-59.png"><img src="https://raw.githubusercontent.com/hua-bang/assert-store/master/Snipaste_2024-05-14_07-57-33.png" alt="Snipaste_2024-05-14_07-57-33.png"><img src="https://raw.githubusercontent.com/hua-bang/assert-store/master/Snipaste_2024-05-14_07-59-03.png" alt="Snipaste_2024-05-14_07-59-03.png"><img src="https://raw.githubusercontent.com/hua-bang/assert-store/master/Snipaste_2024-05-14_08-01-34.png" alt="Snipaste_2024-05-14_08-01-34.png"></p><p>OpenAI 春晚发布了全新升级的GPT-4o模型、ChatGPT 桌面应用，以及部分改进和新功能😊。这次发布会包含了以下令人瞩目的特性：</p><p>🌟 多模态交流：GPT-4o能够无缝切换语音、文本和视觉交流，这意味着它可以理解图片、视频，甚至实时语音对话，就像电影《Her》里的AI一样！</p><p>🔍 视觉能力：它的视觉识别能力也是惊人的，无论是数学题、代码还是人脸情绪，都能快速准确识别。</p><p>🗣️ 语音交流：GPT-4o的语音交流速度快到惊人，几乎和人类反应时间一样快，而且可以随时打断，实时响应，情感丰富。</p><p>🌐 多语言支持：它还是一个多语言模型，50种语言性能全面提升，特别是中文，token消耗大幅减少，交流更高效。</p><p>💻 桌面应用：OpenAI还推出了桌面客户端，Mac和Windows版本即将到来，让AI更贴近我们的日常生活。</p><p>📈 API优势：对于开发者来说，GPT-4o的API速度快了一倍，价格便宜了一半，访问限制提高了五倍，这无疑是巨大的福音。</p><p>🌟 免费用户体验：OpenAI的GPT-4o模型对所有ChatGPT用户免费开放，这代表了一种对AI技术普及的积极推动。免费用户将可以体验到GPT-4o模型的基础功能，如文本生成和简单的图像识别，这为大众提供了一个接触和了解先进AI技术的机会。</p><p>📈 性能提升：无论是免费用户还是Plus用户，都能从GPT-4o的性能提升中受益。更快的响应速度和更准确的识别能力，将极大地增强用户体验。</p><p><a href="https://www.xiaohongshu.com/search_result?keyword=AIGC&amp;type=54&amp;source=web_note_detail_r10" target="_blank" rel="noreferrer">#AIGC</a>  <a href="https://www.xiaohongshu.com/search_result?keyword=openai&amp;type=54&amp;source=web_note_detail_r10" target="_blank" rel="noreferrer">#openai</a>  <a href="https://www.xiaohongshu.com/search_result?keyword=GPT&amp;type=54&amp;source=web_note_detail_r10" target="_blank" rel="noreferrer">#GPT</a>  <a href="https://www.xiaohongshu.com/search_result?keyword=ChatGPT&amp;type=54&amp;source=web_note_detail_r10" target="_blank" rel="noreferrer">#ChatGPT</a>  <a href="https://www.xiaohongshu.com/search_result?keyword=openai%25E5%258F%2591%25E5%25B8%2583%25E4%25BC%259A&amp;type=54&amp;source=web_note_detail_r10" target="_blank" rel="noreferrer">#openai发布会</a></p>',11)]))}const u=t(p,[["render",n]]);export{m as __pageData,u as default};
