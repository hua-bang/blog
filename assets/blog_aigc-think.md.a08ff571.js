import{_ as t,o,c as i,Q as e}from"./chunks/framework.3f790e32.js";const I=JSON.parse('{"title":"AIGC 思考","description":"","frontmatter":{"title":"AIGC 思考","customTag":"blog>互联网","editLink":true},"headers":[],"relativePath":"blog/aigc-think.md","filePath":"blog/aigc-think.md","lastUpdated":1705159004000}'),l={name:"blog/aigc-think.md"},n=e('<h1 id="aigc-思考" tabindex="-1">AIGC 思考 <a class="header-anchor" href="#aigc-思考" aria-label="Permalink to &quot;AIGC 思考&quot;">​</a></h1><div class="tip custom-block"><p class="custom-block-title">TIP</p><p><strong>Tags</strong>: AIGC, 互联网</p><p><strong>Date</strong>: August 27, 2023 10:00 PM</p></div><p>周末两天分别跑了两场有关 AIGC 的活动，</p><p>个人有了更多关于 AIGC 信息输入，</p><p>自个也做了点理解，以及一些个人思考。</p><p>下方先说一下，本次活动给我带来的信息输入 &amp;&amp; 个人理解</p><ul><li><strong><strong>工作流与 AI 的结合</strong></strong>：日常的工作可以抽象成一套流程/机制，在具体的流程和机制中结合 AI 能力。</li><li><strong><strong>数据在 AIGC 中的角色</strong></strong>：模型日后可能差异不会那么大，之后私有数据的差异化可能更重要。</li><li>LLM as a general knowledge runner：也许未来，我们能将我们的个人知识库 + LLM + 工作流结合，构建一套 Agent 能力，塑造一个系统。</li><li>软件工程项目管理 + AIGC：软件工程项目管理的流程，可以结合不同的 AIGC 能力，去做不同的处理。</li><li>AIGC <strong><strong>市场竞争</strong></strong>：目前越来越多的 AIGC 产品出来，竞争过大，可以试着做对应的供给方，比如芯片，或者可能提供让开发者低成本开发大模型的能力/平台。</li><li>Prompt Engineering：提示词工程也可以抽象出一些场景，但还是要实践和归纳。</li><li>不要过分依赖套壳：目前也许套壳 + 想法可以落地一个应用，但可能没有太多的技术的壁垒，除非你的业务认知会足够优势，不然可能会容易被模仿和超越。</li><li>CVP: ChatGPT / LLM + Vector DB + Prompt 实现知识库 嵌入 LLM。大概了解了一些概念，通过将文档信息切分成向量，从而进行向量存储，后续当用户提问，检索向量对应内容，将内容 + 用户的意图 + promot 传给 LLM，从而实现知识库检索。</li></ul><p>感谢活动中各位嘉宾的分享，实际分享的内容远比我上述的多。</p><p>总体来说，即使最近感觉 AI 热度没以前那么强，</p><p>但这次活动让我感觉，也许是发展的领域我们接触的比较少，</p><p>毕竟可能日常接触多的是 C 端的 ChatBot 等应用层的东西，</p><p>而模型和基建层，可能我们接触的稍微少了点。</p><p>最后，也记录下自己的一点小思考吧。</p><ol><li>模型的“幻觉“问题：虽然我们可以通过判断力或者 Prompt 去尽量规避，但还是有一定的成本，不知道未来有没有什么办法可以更好地面对这种情况？</li><li>目前的 AIGC 在某些场景下可能不是纯 AIGC（可能 AIGC 输出的内容不能直接使用），更多的场景可能是 UGC + AIGC，那未来比较成熟的 AIGC 的场面又会是怎么样的。</li><li>个人感觉： AIGC 可能替代不了优质的 UGC / 真实感情的内容。一个 Content 已经经过用户的精细处理，变成了优质内容，那这个在用 AIGC 去处理这些内容，可能会适得其反。</li><li>知识库 + LLM + WorkFlow: 也许未来的 LLM 真的可以做我们自己的 knowledge runner， 但前提是个人可能得具体地去构建自己的知识体系、工作流、以及和 LLM 链接。</li></ol>',14),a=[n];function r(s,p,g,c,C,A){return o(),i("div",null,a)}const d=t(l,[["render",r]]);export{I as __pageData,d as default};
